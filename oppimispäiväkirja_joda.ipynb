{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oppimispäiväkirja\n",
    "\n",
    "Vikko 1\n",
    "\n",
    "En päässyt osallistumaan ensimmäisen luentoviikon opetukseen livenä, mutta katsoin luentotallenteen jälkikäteen. Mielestäni luento ei ollut kovinkaan interaktiivinen, joten en kokenut ainakaan ensimmäisen viikon osalta suurta arvon menetystä, vaikka en päässytkään osallistumaan luennolle. Tästä päästäänkin ensimmäiseenluentojen kehitysehdotukseeni:\n",
    "\n",
    "1) Toivoisin luennoille edes jonkun interaktiivisen osan. Varsinkin näin etänä pelkkää luennointia on välillä todella puuduttavaa kuunneela, vaikka asia sinänsä olisikin mielenkiintoista.\n",
    "\n",
    "Luennolla oli paljon ennestään tuttua asiaa, kuten datatieteen osa-alueet ja datan laadun komponentit. Olin kuullut jo ennen luentoa, että datatiede yhdistää viestinnän, tilastotieteen, ohjelmoinnin ja liiketoiminnan. Koska osa-alueita on monia, on datatiedettä järkevintä toteuttaa tiimeissä, sillä harva hallitsee kaikki osa-alueet täydellisesti. Luennolla keskusteltiin myös Pythonin käyttämisestä datatieteen työvälineenä ja vertailtiin sitä käyttöliittymällisten järjestelmien käyttöön, kuten power BI:hin. Molemmat lähestymistavat olivat minulle tuttuja, mutta en ollut tullut ajatelleeksi näiden vertailua keskenään, sillä mielestäni lähestymistavat vastaavat melko erilaisiin ongelmiin. Luennolla kuitenkin todettiin Pythonin eduiksi toistettavuus, mahdollisuus isompien datamassojen käsittelyyn, ylipäätään enemmän mahdollisuuksia datan käsittelyyn, sekä yhteisön tuki netissä. Tiedostin nämä Pythonin edut jo aikaisemminkin ja Stack Overflown tuki onkin ollut minullekin korvaamatonta useissa aikaisemmissa koulu- ja työprojekteissa.\n",
    "\n",
    "Mielenkiintoisena asiana minulle jäi luennolta mieleen ajatus siitä, kuka todellisuudessa pääsee käsiksi hypetettyihin suuriin datamassoihin. Luennolla mainittiin, että suurin osa datasta on todellisuudessa vain suurten alustatrjoajien saatavilla. Tämä oli mielnkiintoinen näkökulma, sillä datan määrän kasvusta ollaan puhuttu jo ihan riittämiin eri kursseilla, mutta todellisuus on kuitenkin se, ettei kaikilla ole samanlaisia mahdollisuuksia datan hyödyntämiseen.\n",
    "\n",
    "En päässyt osallistumaan myöskään perjantain koodiklinikalle, mutta katsoin siitäkin tulleen tallenteen jälkikäteen. Koodiklinikalla kaikki oli käytännössä uutta asiaa minulle. \n",
    "\n",
    "Viikolla oppimani asiat:\n",
    "\n",
    "1) Tosiasia siitä, ketkä oikeasti pääsevät käsiksi hypetettyihin \"valtaviin datamassoihin\"\n",
    "2) Datasetin avaaminen ja tarkastelu JupyterLab ympäristössä\n",
    "\n",
    "\n",
    "Alla olevat koodiesimerkit on tehty ensimmäisen koodiklinikan esimerkkien pohjalta, omaa koodia ei ole vielä kirjoitettu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Declare the libraries that will be used\n",
    "import pandas as pd\n",
    "# Used to plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of attributes: ['Transaction_date', 'Product', 'Price', 'Payment_Type', 'Name', 'City', 'State', 'Country', 'Account_Created', 'Last_Login', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/jodatut/2020/raw/master/koodiesimerkit/SalesJan2009.csv'\n",
    "\n",
    "# Use pandas to import data\n",
    "orig_df = pd.read_csv(url)\n",
    "\n",
    "# To keep original dataframe for referencing\n",
    "df = orig_df.copy()\n",
    "print('List of attributes:', df.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction_date   Product  Price Payment_Type               Name  \\\n",
      "0      1/2/09 6:17  Product1   1200   Mastercard           carolina   \n",
      "1      1/2/09 4:53  Product1   1200         Visa             Betina   \n",
      "2     1/2/09 13:08  Product1   1200   Mastercard  Federica e Andrea   \n",
      "3     1/3/09 14:44  Product1   1200         Visa              Gouya   \n",
      "4     1/4/09 12:56  Product2   3600         Visa            Gerd W    \n",
      "\n",
      "                           City     State         Country Account_Created  \\\n",
      "0                      Basildon   England  United Kingdom     1/2/09 6:00   \n",
      "1  Parkville                           MO   United States     1/2/09 4:42   \n",
      "2  Astoria                             OR   United States    1/1/09 16:21   \n",
      "3                        Echuca  Victoria       Australia   9/25/05 21:13   \n",
      "4  Cahaba Heights                      AL   United States  11/15/08 15:47   \n",
      "\n",
      "     Last_Login   Latitude   Longitude  \n",
      "0   1/2/09 6:08  51.500000   -1.116667  \n",
      "1   1/2/09 7:49  39.195000  -94.681940  \n",
      "2  1/3/09 12:32  46.188060 -123.830000  \n",
      "3  1/3/09 14:22 -36.133333  144.750000  \n",
      "4  1/4/09 12:45  33.520560  -86.802500  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction_date     object\n",
      "Product              object\n",
      "Price                 int64\n",
      "Payment_Type         object\n",
      "Name                 object\n",
      "City                 object\n",
      "State                object\n",
      "Country              object\n",
      "Account_Created      object\n",
      "Last_Login           object\n",
      "Latitude            float64\n",
      "Longitude           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_date</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Payment_Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Account_Created</th>\n",
       "      <th>Last_Login</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02 06:17:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Mastercard</td>\n",
       "      <td>carolina</td>\n",
       "      <td>Basildon</td>\n",
       "      <td>England</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>2009-01-02 06:00:00</td>\n",
       "      <td>2009-01-02 06:08:00</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>-1.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02 04:53:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Betina</td>\n",
       "      <td>Parkville</td>\n",
       "      <td>MO</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>2009-01-02 04:42:00</td>\n",
       "      <td>2009-01-02 07:49:00</td>\n",
       "      <td>39.195000</td>\n",
       "      <td>-94.681940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02 13:08:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Mastercard</td>\n",
       "      <td>Federica e Andrea</td>\n",
       "      <td>Astoria</td>\n",
       "      <td>OR</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>2009-01-01 16:21:00</td>\n",
       "      <td>2009-01-03 12:32:00</td>\n",
       "      <td>46.188060</td>\n",
       "      <td>-123.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-03 14:44:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Gouya</td>\n",
       "      <td>Echuca</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>2005-09-25 21:13:00</td>\n",
       "      <td>2009-01-03 14:22:00</td>\n",
       "      <td>-36.133333</td>\n",
       "      <td>144.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-04 12:56:00</td>\n",
       "      <td>Product2</td>\n",
       "      <td>3600</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Gerd W</td>\n",
       "      <td>Cahaba Heights</td>\n",
       "      <td>AL</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>2008-11-15 15:47:00</td>\n",
       "      <td>2009-01-04 12:45:00</td>\n",
       "      <td>33.520560</td>\n",
       "      <td>-86.802500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2009-01-01 04:24:00</td>\n",
       "      <td>Product3</td>\n",
       "      <td>7500</td>\n",
       "      <td>Amex</td>\n",
       "      <td>Pamela</td>\n",
       "      <td>Skaneateles</td>\n",
       "      <td>NY</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>2008-12-28 17:28:00</td>\n",
       "      <td>2009-03-01 07:21:00</td>\n",
       "      <td>42.946940</td>\n",
       "      <td>-76.429440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2009-01-08 11:55:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Diners</td>\n",
       "      <td>julie</td>\n",
       "      <td>Haverhill</td>\n",
       "      <td>England</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>2006-11-29 13:31:00</td>\n",
       "      <td>2009-03-01 07:28:00</td>\n",
       "      <td>52.083333</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2009-01-12 21:30:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Julia</td>\n",
       "      <td>Madison</td>\n",
       "      <td>WI</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>2008-11-17 22:24:00</td>\n",
       "      <td>2009-03-01 10:14:00</td>\n",
       "      <td>43.073060</td>\n",
       "      <td>-89.401110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2009-01-02 06:17:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Mastercard</td>\n",
       "      <td>carolina</td>\n",
       "      <td>Basildon</td>\n",
       "      <td>England</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>2009-01-02 06:00:00</td>\n",
       "      <td>2009-01-02 06:08:00</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>-1.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2009-01-02 04:53:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>1200</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Betina</td>\n",
       "      <td>Parkville</td>\n",
       "      <td>MO</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>2009-01-02 04:42:00</td>\n",
       "      <td>2009-01-02 07:49:00</td>\n",
       "      <td>39.195000</td>\n",
       "      <td>-94.681940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Transaction_date   Product  Price Payment_Type               Name  \\\n",
       "0   2009-01-02 06:17:00        P1   1200   Mastercard           carolina   \n",
       "1   2009-01-02 04:53:00        P1   1200         Visa             Betina   \n",
       "2   2009-01-02 13:08:00        P1   1200   Mastercard  Federica e Andrea   \n",
       "3   2009-01-03 14:44:00        P1   1200         Visa              Gouya   \n",
       "4   2009-01-04 12:56:00  Product2   3600         Visa            Gerd W    \n",
       "..                  ...       ...    ...          ...                ...   \n",
       "995 2009-01-01 04:24:00  Product3   7500         Amex             Pamela   \n",
       "996 2009-01-08 11:55:00        P1   1200       Diners              julie   \n",
       "997 2009-01-12 21:30:00        P1   1200         Visa             Julia    \n",
       "998 2009-01-02 06:17:00        P1   1200   Mastercard           carolina   \n",
       "999 2009-01-02 04:53:00        P1   1200         Visa             Betina   \n",
       "\n",
       "                             City     State         Country  \\\n",
       "0                        Basildon   England  UNITED KINGDOM   \n",
       "1    Parkville                           MO   UNITED STATES   \n",
       "2    Astoria                             OR   UNITED STATES   \n",
       "3                          Echuca  Victoria       AUSTRALIA   \n",
       "4    Cahaba Heights                      AL   UNITED STATES   \n",
       "..                            ...       ...             ...   \n",
       "995  Skaneateles                         NY   UNITED STATES   \n",
       "996                     Haverhill   England  UNITED KINGDOM   \n",
       "997  Madison                             WI   UNITED STATES   \n",
       "998                      Basildon   England  UNITED KINGDOM   \n",
       "999  Parkville                           MO   UNITED STATES   \n",
       "\n",
       "        Account_Created          Last_Login   Latitude   Longitude  \n",
       "0   2009-01-02 06:00:00 2009-01-02 06:08:00  51.500000   -1.116667  \n",
       "1   2009-01-02 04:42:00 2009-01-02 07:49:00  39.195000  -94.681940  \n",
       "2   2009-01-01 16:21:00 2009-01-03 12:32:00  46.188060 -123.830000  \n",
       "3   2005-09-25 21:13:00 2009-01-03 14:22:00 -36.133333  144.750000  \n",
       "4   2008-11-15 15:47:00 2009-01-04 12:45:00  33.520560  -86.802500  \n",
       "..                  ...                 ...        ...         ...  \n",
       "995 2008-12-28 17:28:00 2009-03-01 07:21:00  42.946940  -76.429440  \n",
       "996 2006-11-29 13:31:00 2009-03-01 07:28:00  52.083333    0.433333  \n",
       "997 2008-11-17 22:24:00 2009-03-01 10:14:00  43.073060  -89.401110  \n",
       "998 2009-01-02 06:00:00 2009-01-02 06:08:00  51.500000   -1.116667  \n",
       "999 2009-01-02 04:42:00 2009-01-02 07:49:00  39.195000  -94.681940  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Use general apply function\n",
    "caps = lambda x: x.upper()\n",
    "\n",
    "# def caps(x):\n",
    "#     return x.upper()\n",
    "\n",
    "df['Country'] = df['Country'].apply(caps)\n",
    "\n",
    "def test(x):\n",
    "    if x == \"Product1\":\n",
    "        return \"P1\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df['Product'] = df['Product'].apply(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# New column to calculate logins within a week\n",
    "df['Login_week'] = \"\"\n",
    "\n",
    "def lastweek(x):\n",
    "    date = pd.Timestamp(2009, 2, 2)\n",
    "    date_diff = pd.Timedelta(date-x).days\n",
    "    if date_diff < 7:\n",
    "        return \"Last week\"\n",
    "    else:\n",
    "        return \"Not last week\"\n",
    "    \n",
    "df['Login_week'] = df['Last_Login'].apply(lastweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Transaction_date   Product  Price Payment_Type        Name  \\\n",
      "289 2009-01-26 03:43:00        P1   1200   Mastercard       Wendy   \n",
      "290 2009-01-26 03:49:00  Product2   3600   Mastercard        Jane   \n",
      "291 2009-01-11 13:16:00  Product2   3600         Visa      shelby   \n",
      "292 2009-01-22 15:32:00        P1   1200   Mastercard        Tara   \n",
      "293 2009-01-09 14:25:00        P1   1200         Amex       James   \n",
      "..                  ...       ...    ...          ...         ...   \n",
      "993 2009-01-22 14:25:00        P1   1200         Visa  Hans-Joerg   \n",
      "994 2009-01-28 05:36:00  Product2   3600         Visa  Christiane   \n",
      "995 2009-01-01 04:24:00  Product3   7500         Amex      Pamela   \n",
      "996 2009-01-08 11:55:00        P1   1200       Diners       julie   \n",
      "997 2009-01-12 21:30:00        P1   1200         Visa      Julia    \n",
      "\n",
      "                             City                       State         Country  \\\n",
      "289  Lake Mahopac                                          NY   UNITED STATES   \n",
      "290                          Biot  Provence-Alpes-Cote d'Azur          FRANCE   \n",
      "291  Plantation                                            FL   UNITED STATES   \n",
      "292                      Killiney                      Dublin         IRELAND   \n",
      "293                          Guer                    Brittany          FRANCE   \n",
      "..                            ...                         ...             ...   \n",
      "993                       Belfast            Northern Ireland  UNITED KINGDOM   \n",
      "994                   Black River                 Black River       MAURITIUS   \n",
      "995  Skaneateles                                           NY   UNITED STATES   \n",
      "996                     Haverhill                     England  UNITED KINGDOM   \n",
      "997  Madison                                               WI   UNITED STATES   \n",
      "\n",
      "        Account_Created          Last_Login   Latitude  Longitude Login_week  \n",
      "289 2009-01-26 03:10:00 2009-01-26 03:10:00  41.372220 -73.733890  Last week  \n",
      "290 2008-03-01 00:00:00 2009-01-26 03:18:00  43.633333   7.100000  Last week  \n",
      "291 2009-01-11 12:20:00 2009-01-26 03:42:00  26.121940 -80.143610  Last week  \n",
      "292 2007-02-27 11:35:00 2009-01-26 04:32:00  53.252222  -6.112500  Last week  \n",
      "293 2008-04-07 00:00:00 2009-01-26 05:32:00  47.900000  -2.116667  Last week  \n",
      "..                  ...                 ...        ...        ...        ...  \n",
      "993 2008-11-10 12:15:00 2009-03-01 03:37:00  54.583333  -5.933333  Last week  \n",
      "994 2009-01-09 08:10:00 2009-03-01 04:40:00 -20.360278  57.366111  Last week  \n",
      "995 2008-12-28 17:28:00 2009-03-01 07:21:00  42.946940 -76.429440  Last week  \n",
      "996 2006-11-29 13:31:00 2009-03-01 07:28:00  52.083333   0.433333  Last week  \n",
      "997 2008-11-17 22:24:00 2009-03-01 10:14:00  43.073060 -89.401110  Last week  \n",
      "\n",
      "[709 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[ df['Login_week']=='Last week' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viikko 2\n",
    "\n",
    "Toisella viikolla osallistuin luennolle livenä. Datan siivoaminen on minulle tuttu termi aikaisemmista opinnoistani. Käytännön tasolla en ole kuitenkaan päässyt kokeilemaan sitä Excelillä tehtävää työtä lukuunottamatta. Onkin mielenkiinotista päästä kokeilemaan tätäkin ohjelmallisesti. Datan laatua on korostettu tämän vuoden aikana melkeinpä jokaisella käymälläni kurssilla, joten siihen liittyvät aiheet eivät olleet minulle uusia. On kuitenkin mielenkiintoista päästä kokeilemaan näitä teoriassa opittuja asioita käytännössä, siitä minulla ei vielä ole kokemusta.\n",
    "\n",
    "Mielestäni luennolla oli mielenkiintoista termien vertailua (liiketoimintatiedon hallinta vs datatiede), mutta oman kokemukseni mukaan termien vertailu ei välttämättä ole mielekästä. Tein itse kandityöni liiketoimintatiedon hallintaan liittyen ja havaitsin tietoa etsiessäni, että termejä (BI, business analytics, data analytics…) käytettiin paljon ristiin eri tutkimuksissa.\n",
    "\n",
    "Datan ostaminen ja rajapintojen käyttäminen olivat minulle tuttuja datan keräämisen keinoja, mutta datan raapiminen ja ryömiminen olivat minulle uusia asioita. Raavinnan eettisyys ja laillisuus olivat mielestäni mielenkiintoisia näkökulmia luennolla. Laillisuus ei toki mielestäni pitäisi olla kovinkaan moniselitteistä toisin kuin eettisyys. \n",
    "\n",
    "Viikon opit\n",
    "1) Ruudun raavinta käsitteenä ja vähän käytännössäkin\n",
    "2) Ryömiminen käsitteenä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viikko 3\n",
    "\n",
    "Osallistuin kolmannelle luennolle livenä. Koneoppimiseen liittyvä luento oli ehkäpä luennoista se, jota odotin eniten. Minulla on jonkin verran aikaisempaa kokemusta koneoppimisesta aikasisempien työkokemusteni vuoksi. Siksi koneoppimisen peruskäistteet, kuten suprvised ja unsupervised learning olivat minulle ennestään tuttuja. Myös koneoppimisen perus käyttötarkoitukset ja mallien opettaminen olivat minulle tuttuja asioita. Kuitenkin aikaisempi käytännön kokemukseni painottuu lähinnä kuvadataan ja siihen liittyviin kirjastoihin, kuten tensorflown object detection-ominaisuuksiin, joten toivon oppivani lisää numeerisen datan käsittelystä koneoppimisen avulla.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
